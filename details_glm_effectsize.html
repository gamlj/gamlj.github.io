<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Details: GLM effect size indices</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110344212-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110344212-1');
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>




<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">GAMLj</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="glm.html">GLM</a>
</li>
<li>
  <a href="mixed.html">Mixed</a>
</li>
<li>
  <a href="gzlm.html">Generalized Models</a>
</li>
<li>
  <a href="gzlmmixed.html">Generalized Mixed Models</a>
</li>
<li>
  <a href="examples.html">Examples and Details</a>
</li>
<li>
  <a href="release_notes.html">Release notes</a>
</li>
<li>
  <a href="vignettes.html">GAMLj in R</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/gamlj/gamlj">View on Github</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Details: GLM effect size indices</h1>

</div>


<p><span class="keywords"> <span class="keytitle"> keywords </span> jamovi, GLM, effect size indices, omega-squared, eta-squared, epsilon-squared </span></p>
<p><span class="version"> <span class="versiontitle"> GALMj version ≥ </span> 2.6.1 </span></p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Standardized Effect size indices produced by GLM module are the following:</p>
<ul>
<li><span class="math inline">\(\beta\)</span> : standardized regression coefficients</li>
<li><span class="math inline">\(\eta^2\)</span>: (semi-partial) eta-squared</li>
<li><span class="math inline">\(\eta^2\)</span>p : partial eta-squared</li>
<li><span class="math inline">\(\omega^2\)</span> : omega-squared</li>
<li><span class="math inline">\(\omega^2\)</span>p : partial omega-squared</li>
<li><span class="math inline">\(\epsilon^2\)</span> : epsilon-squared</li>
<li><span class="math inline">\(\epsilon^2\)</span>p : partial epsilon-squared</li>
</ul>
<p>All coefficients but the betas are computed with the approapriate function of the R package <a href="https://cran.r-project.org/web/packages/effectsize/index.html">effectsize</a>, with some adjustment.</p>
</div>
<div id="beta-beta" class="section level1">
<h1><span class="math inline">\(\beta\)</span> : beta</h1>
<p>For continuous variables, it simply corresponds to the B coefficient obtained after standardizing all variables in the model. The standardization of the continuous variables is done before any transformation is applied, so if a complex model requires interaction or polynomial terms, the terms are computed after standardization, and the <span class="math inline">\(\beta\)</span> are consistent.</p>
<p>For categorical variables, however, some comments are in order: Categorical variables are not standardized in <span class="gamlj">GAMLj</span>, so the <span class="math inline">\(\beta\)</span> should be interpreted in terms of standardized differences in the dependent variable between the levels contrasted by the corresponding contrast. Consider the following example: Two groups (variable <code>groups</code>) of size 20 and 10 respectively, are compared on a variable Y. If one uses <span class="gamlj">GAMLj</span> default contrast coding (<code>simple</code>), the B is the difference in groups means. The <span class="math inline">\(\beta\)</span> is the difference between the average z-scores of the dependent variable between the two groups. Assume these are the results:</p>
<p><img src=" details/glm/effectsize_example1_1.png " class="img-responsive" alt=""></p>
<p>The beta is 0.352, so it means that if we compute the mean difference between groups in the standardized <em>y</em>, we obtain 0.352. In fact.</p>
<p><img src=" details/glm/effectsize_example1_2.png " class="img-responsive" alt=""></p>
<p>However, the <span class="math inline">\(\beta\)</span> you obtain is not the correlation between <em>zy</em> and <em>groups</em>. The correlation is 0.169:</p>
<p><img src=" details/glm/effectsize_example1_3.png " class="img-responsive" alt=""></p>
<p>Why is there this discrepancy? Because the groups are not balanced, so when the correlation is computed, the variable <em>groups</em> is standardized, so the contrast coding values depend on the relative size of the groups. The actual groups coding values used by the Pearson’s correlations are the following:</p>
<p><img src=" details/glm/effectsize_example1_4.png " class="img-responsive" alt=""></p>
<p>Thus, the correlation corresponds to running a regression with <em>zy</em> as dependent variables and a continuous variable featuring either -.695 or 1.390 as values. The <span class="math inline">\(\beta\)</span> yielded by <span class="gamlj">GAMLj</span>, instead, is the mean difference between X levels on the standardized Y. Please notice that other software may yield different <span class="math inline">\(\beta\)</span>’s for categorical variables.</p>
<p>If the groups are balanced and homeschedastic, the <span class="math inline">\(\beta\)</span> associated with a <code>simple</code> contrast corresponds to the fully standardized coefficient.</p>
</div>
<div id="eta2-semi-partial-eta-squared" class="section level1">
<h1><span class="math inline">\(\eta^2\)</span>: (semi-partial) eta-squared</h1>
<p>This is the proportion of total variance uniquely explained by the associated effect. Being <span class="math inline">\(SS_{eff}\)</span> the sum of squares of the effect, <span class="math inline">\(SS_{res}\)</span> the sum of squares of the residuals or of SS error, and <span class="math inline">\(SS_{model}\)</span> the sum of sum of squares of the whole model, we have:</p>
<p><span class="math display">\[\eta^2={{SS_{eff} \over {SS_{model}+SS_{res}}}}\]</span></p>
<p>where <span class="math inline">\(SS_{model}+SS_{res}=SS_{total}\)</span> and <span class="math inline">\(SS_{total}=\sum(y_i-\bar{y})^2\)</span> and <span class="math inline">\(SS_{model}=\sum(\hat{y_i}-\bar{\hat{y}})^2\)</span>.</p>
<p>Please notice that although the computation of the effect size indexes and their confidence intervals is carried out employing <a href="https://github.com/easystats/effectsize">effectsize R package</a>, <span class="gamlj">GAMLj</span> makes a correction to the computation of <span class="math inline">\(\eta^2\)</span> and of the other non-partial indices. <code>effectsize</code> R package, infact, defines the total sum of squares as <span class="math inline">\(SS_{total}^*=\sum{SS_{f}+SS_{res}}\)</span>, where <span class="math inline">\(f\)</span> is any effect in the model. For balanced designs and many other models, <span class="math inline">\(SS_{total}^*=SS_{total}\)</span>, so no issue arises. However, there are certain models in which <span class="math inline">\(SS_{total}^*\ne SS_{total}\)</span>, and so the index looses some of its properties when computed based on <span class="math inline">\(SS_{total}^*\)</span>. <span class="gamlj">GAMLj</span> operates a correction such that all the non-partial indeces are always computed based on <span class="math inline">\(SS_{total}=SS_{model}+SS_{res}\)</span>.</p>
<p>With the correction, one property <span class="math inline">\(\eta^2\)</span> retains even when <span class="math inline">\(SS_{total}^*\ne SS_{total}\)</span> is that <span class="math inline">\(\eta^2=r_{sp}^2\)</span>, where <span class="math inline">\(r_{sp}\)</span> is the semi-partial correlation <span class="citation">(<a href="#ref-cohen2014applied" role="doc-biblioref">Cohen, West, and Aiken 2014</a>)</span>. We can use the <code>exercise</code> dataset from <span class="citation">(<a href="#ref-cohen2014applied" role="doc-biblioref">Cohen, West, and Aiken 2014</a>)</span> to see this in practice (refer to <a href="glm_example1.html">GLM: Multiple regression, moderated regression, and simple slopes</a> for a complete analysis). If we run a multiple regression <code>yendu~xage+zexer</code> and ask for the <span class="math inline">\(\eta^2\)</span>’s, we obtain the following results:</p>
<p><img src="details/glm/eta1.png" class="img-responsive" alt=""></p>
<p>Going in <span class="jamovi">jamovi</span>, <span class="option">Regression-&gt;Partial correlation</span> we can compute the semi-partial correlation of each IV coviariating the other. This gives:</p>
<p><img src="details/glm/eta2.png" class="img-responsive" alt=""></p>
<p>Squaring it gives <span class="math inline">\(r_{yx.z}^2=-0.230^2=0.0529\)</span>, which is equal to the corrisponding <span class="math inline">\(\eta^2=.053\)</span>.</p>
<p><img src="details/glm/eta3.png" class="img-responsive" alt=""></p>
<p>Squaring the second <span class="math inline">\(r_{sp}^2\)</span> gives <span class="math inline">\(r_{yz.x}^2=0.388^2=0.1504664\)</span>, considering rounding, which is equal to the corrisponding <span class="math inline">\(\eta^2=.150\)</span>.</p>
<p>If we used <span class="math inline">\(SS_{total}^*=\sum{SS_{f}}+SS_{res}\)</span>, results would be:</p>
<ul>
<li><span class="math inline">\(SS_{total}^*=1516+4298+23810=29624\)</span></li>
<li><span class="math inline">\(SS_{yx.z}^*=1516/29624 =0.0511747\)</span></li>
<li><span class="math inline">\(SS_{yz.x}^*=4298/29624 =0.1450851\)</span></li>
</ul>
<p>that are clearly not corresponding to the <span class="math inline">\(r_{sp}^2\)</span>, as they should be. We should note, however, that the two methods of estimation usually give very similar results, even when <span class="math inline">\(SS_{total}^* \ne SS_{total}\)</span> and exact the same results when <span class="math inline">\(SS_{total}^*=SS_{total}\)</span>.</p>
<p>The same reasoning holds for all the non-partial indices.</p>
<div id="isnt-this-weird-technical-stuff" class="section level2">
<h2>Isn’t this weird (technical stuff)?</h2>
<p>For many people, the fact that <span class="math inline">\(\sum{SS_{f}} \ne SS_{model}\)</span> may come as a surprise. Maybe because in the ANOVA tradition, with balanced designs, <span class="math inline">\(\sum{SS_{f}}\)</span> is always equal to <span class="math inline">\(SS_{model}\)</span>, or maybe because it would be nicer if it was always like in the ANOVA. Since we have to accept that in the GLM <span class="math inline">\(\sum{SS_{f}}\)</span> is not necessarily equal to <span class="math inline">\(SS_{model}\)</span>, let us see when this happens.</p>
<p>There are two cases: The easiest to understand is when <span class="math inline">\(\sum{SS_{f}} \lt SS_{model}\)</span>. This case happens when the independent variables are correlated so each variable explains a unique part of the variance, but the model sum of square involves also some shared variance, which ends up in <span class="math inline">\(SS_{model}\)</span> but not in <span class="math inline">\(\sum{SS_{f}}\)</span>.</p>
<p>A little trickier is the case when <span class="math inline">\(\sum{SS_{f}} \gt SS_{model}\)</span>, because it seems strange that the sum of effects is larger than the overall combined effect.</p>
<p>Consider a regression <span class="math inline">\(y=a+b_{yx.z}x+b_{yz.x}z\)</span>. Recall the the <span class="math inline">\(SS_{yx.z}\)</span> (<span class="math inline">\(x\)</span> explains <span class="math inline">\(y\)</span> keeping constant <span class="math inline">\(z\)</span>) is computed as <span class="math inline">\(SS_{total}-SS_{yz}\)</span>, where <span class="math inline">\(SS_{yz}\)</span> is the sum of squares explained by <span class="math inline">\(x\)</span> without <span class="math inline">\(z\)</span> in the model, and <span class="math inline">\(SS_{yz.x}=SS_{total}-SS_{yx}\)</span>. It follows that the <span class="math inline">\(\sum{SS_f}=2\cdot SS_{total}-SS_{yx}-SS_{yz}\)</span> is larger than <span class="math inline">\(SS_{total}\)</span> when <span class="math inline">\(SS_{total} &gt; SS_{yx}+SS_{yz}\)</span>. This necessarily means that at least one variable explains more variance while keeping constant the other than alone.</p>
<p>Indeed, in the example above about exercising, the SS of <em>age</em> alone is 452, and <em>exer</em> alone is 3234, which sum to 3686, less than 4751, the multiple regression model SS.</p>
<p>The question is now: when does this happen? Well, it happens when the <span class="math inline">\(B_{yx}\)</span>, the coefficient associated with <span class="math inline">\(x\)</span> in simple regression, is smaller (in absolute value) than the partial coefficient of <span class="math inline">\(B_{yx.z}\)</span> of a multiple regression. Because <span class="math inline">\(B_{yx.z}=B_{yx} - B_{yz.x}\cdot B_{xz}\)</span>, this happens when <span class="math inline">\(B_{yx}\)</span> and <span class="math inline">\(B_{yz.x}\cdot B_{zx}\)</span> have different signs: therefore, we have a suppression effect!</p>
<p>In the example above, focusing on <em>age</em>, we have <span class="math inline">\(B_{yx.z}=-.257\)</span>, <span class="math inline">\(B_{yz.x}=.916\)</span> and <span class="math inline">\(B_{zx}=.134\)</span>, thus <span class="math inline">\(B_{yz.x}\cdot B_{zx}=.916*.134=0.122744\)</span>, which has a different sign than <span class="math inline">\(B_{yx.z}=-.257\)</span>.</p>
</div>
</div>
<div id="eta2p-partial-eta-squared" class="section level1">
<h1><span class="math inline">\(\eta^2\)</span>p : partial eta-squared</h1>
<p>This is the proportion of partial variance uniquely explained by the associated effect. That is, the variance uniquely explained by the effect expressed as the proportion of variance not explained by the other effects. Here the variance explained by the other effects in the model is completely partialed out. Its formula is:</p>
<p><span class="math display">\[\eta^2p={{SS_{eff} \over {SS_{eff}+SS_{res}}}}\]</span></p>
<p>clearly, if there is only one independent variable, <span class="math inline">\(\eta^2=\eta^2p\)</span></p>
</div>
<div id="omega2-omega-squared" class="section level1">
<h1><span class="math inline">\(\omega^2\)</span> : omega-squared</h1>
<p>This is the <em>expected value in the population</em> of the proportion of variance uniquely explained by the associated effect. In other words, it is the unbiased version of <span class="math inline">\(\eta^2\)</span>. There are different formulas to visualize its computation, here is one. If <span class="math inline">\(df_{res}\)</span> are the degrees of freedon of the residual variance, <span class="math inline">\(df_{eff}\)</span> are the degrees of freedom of the effect, we have:</p>
<p><span class="math display">\[\omega^2={{SS_{eff}-SS_{res} \cdot ({df_{eff}/df_{res}) \cdot }}\over{ SS_{model}+SS_{res}(df_{res}+1)/df_{res}}}\]</span></p>
<p>It’s clear that omega is similat to <span class="math inline">\(\eta^2\)</span>, but applies a correction for the denominator.</p>
</div>
<div id="omega2p-partial-omega-squared" class="section level1">
<h1><span class="math inline">\(\omega^2\)</span>p : partial omega-squared</h1>
<p>This is the <em>expected value in the population</em> of the proportion of <em>partial</em> variance uniquely explained by the associated effect. In other words,it is the unbiased version of <span class="math inline">\(\eta^2p\)</span>. With N being the sample size, We have:</p>
<p><span class="math display">\[\omega^2p={{SS_{eff}-SS_{res} \cdot ({df_{eff}/df_{res}) \cdot }}\over{ SS_{eff}+SS_{res} \cdot [{(N-df_{eff})/df_{res}}]
}}\]</span></p>
<p>It’s clear that omega is similat to <span class="math inline">\(\eta^2p\)</span>, but applies a correction for the degress of freedom. In fact, as N increases, the two indices converge.</p>
</div>
<div id="epsilon2p-epsilon-squared" class="section level1">
<h1><span class="math inline">\(\epsilon^2\)</span>p : epsilon-squared</h1>
<p>Epsilon-squared is another correction of <span class="math inline">\(\eta^2\)</span>, but the correction involves only the estimation of the sum of squares of the effect, not the partial variance on which the effect is compared</p>
<p><span class="math display">\[\epsilon^2={{SS_{eff}-SS_{res} \cdot ({df_{eff}/df_{res}) \cdot }}\over{ SS_{model}+SS_{res}}}\]</span></p>
</div>
<div id="epsilon2p-partial-epsilon-squared" class="section level1">
<h1><span class="math inline">\(\epsilon^2\)</span>p : partial epsilon-squared</h1>
<p>As for the non-partial Epsilon, the partial Epsilon-squared is a correction of <span class="math inline">\(\eta^2p\)</span>, but the correction involves only the estimation of the sum of squares of the effect, not the partial variance on which the effect is compared</p>
<p><span class="math display">\[\epsilon^2p={{SS_{eff}-SS_{res} \cdot ({df_{eff}/df_{res}) \cdot }}\over{ SS_{eff}+SS_{res}}}\]</span></p>
</div>
<div id="simple-effects" class="section level1">
<h1>Simple Effects</h1>
<p>From version 2.6.1 on, all the effect size indices are available also for the simple effects. To compute them, <span class="gamlj">GAMLj</span> extracts the SS of the simple effect from <code>R emmeans</code> F-tests. The SS residuals and SS model is extracted from the model summary, given that both SS do not change when simple effects are computed. Then the indices are computed using the previously described formulas.</p>
<p>In particular, if the simple effect is <span class="math inline">\(se\)</span>: <span class="math display">\[SS_{res}=\sigma^2\cdot df_{res}\]</span></p>
<p>where <span class="math inline">\(\sigma\)</span> is extracted as <code>sigma(model)</code>.</p>
<p><span class="math display">\[SS_{model}={{F_{model}\cdot df_{model}} \cdot {SS_{res} \over {df_{res}}}}\]</span></p>
<p>and</p>
<p><span class="math display">\[SS_{se}={{F_{se}\cdot df_{se}} \cdot {SS_{res} \over {df_{res}}}}\]</span></p>
</div>
<div id="confidence-intervals" class="section level1">
<h1>Confidence intervals</h1>
<p>In option tab <code>Options</code> it is possible to ask additional tables for the effect size indices, containing the effect size indices and their confidence intervals (here an example with the <code>exercise</code> dataset)</p>
<p><img src="details/glm/detail_effectsize1.png" class="img-responsive" alt=""></p>
<p><img src="details/glm/detail_effectsize2.png" class="img-responsive" alt=""></p>
<p>Details for the confidence intervals computation can be found in <a href="https://github.com/easystats/effectsize">Ben-Shachar, Makowski &amp; Lüdecke (2020). Compute and interpret indices of effect size. CRAN</a></p>
<h1>
Comments?
</h1>
<p>
Got comments, issues or spotted a bug? Please open an issue on <a href="https://github.com/gamlj/gamlj/issues"> GAMLj at github“</a> or <a href="mailto:mcfanda@gmail.com">send me an email</a>
</p>
</div>
<div id="additional-references" class="section level1 unnumbered">
<h1 class="unnumbered">Additional references</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-cohen2014applied" class="csl-entry">
Cohen, Patricia, Stephen G West, and Leona S Aiken. 2014. <em>Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences</em>. Psychology press.
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
